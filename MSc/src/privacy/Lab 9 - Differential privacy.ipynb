{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "587816c9",
   "metadata": {},
   "source": [
    "# Lab 9 - Differential Privacy\n",
    "\n",
    "In this lab, we will explore Differential Privacy in Machine Learning Models.\n",
    "\n",
    "Specifically, we will create a private Machine Learning Models using three different methods.  \n",
    "Each method preserves a distinct aspect of privacy, which we will discuss in detail later.\n",
    "\n",
    "1. **Output Perturbation** - Randomized Response \n",
    "2. **Perturbation Data**  - Laplacian Noise\n",
    "3. **Perturbation of the Objective Function** -  Differentially private Empirical Risk Minimization\n",
    "\n",
    "### Materials for the Lab\n",
    "1. Course slides  \n",
    "2. [Christos' Book](https://github.com/olethrosdc/ml-society-science/blob/master/book.pdf)  \n",
    "3. [Differential Privacy Tutorials](https://programming-dp.com/cover.html)  \n",
    "4. [PyTorch Tutorials](https://programming-dp.com)\n",
    "\n",
    "### Libraries\n",
    "1. A privacy-focused library similar to scikit-learn: [Diffprivlib](https://diffprivlib.readthedocs.io/en/latest/)  \n",
    "2. A library for implementing private PyTorch models: [Opacus](https://opacus.ai/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f672b51",
   "metadata": {},
   "source": [
    "## Motivation\n",
    "\n",
    "Differential Privacy is a critical concept in modern machine learning.The primary goal of machine learning models is to learn useful patterns that generalize well, enabling accurate predictions and decisions on unseen data. As discussed in previous labs, deep learning models often contain millions of parameters, which can lead to overfitting due to the \"memorization\" of information within these parameters.\n",
    "\n",
    "This memorization poses a significant risk: sensitive or private information from the training dataset can inadvertently be encoded into the model, potentially harming individual privacy.\n",
    "\n",
    "Differential Privacy aims to address this issue by ensuring that models do not reveal specific details about individuals in the training data while still learning meaningful and generalizable patterns.\n",
    "\n",
    "### Assumptions\n",
    "\n",
    "The general assumption is that an adversary has access to the trained model, including its complete structure and the values of all parameters. Under these conditions, we must ensure that the adversary cannot extract sensitive information about individuals in the dataset. The most common privacy-related concerns include:\n",
    "\n",
    "1. **Membership Inference Attacks**  \n",
    "   - **Goal**: Determine if a specific individual's data was included in the training dataset.\n",
    "\n",
    "2. **Reconstruction Attacks**  \n",
    "   - **Goal**: Reconstruct sensitive features of individuals whose data contributed to the model.\n",
    "\n",
    "For a more detailed overview of these and other related concerns, refer to this resource: [Understanding Privacy Risks](https://arxiv.org/pdf/2011.11819)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8ec64d",
   "metadata": {},
   "source": [
    "<img src=\"./img/attack.png\" alt=\"Effect of Epsilon on Model Accuracy\" width=\"600\">\n",
    "\n",
    "Paper: [Model inversion attacks that exploit confidence information and basic countermeasures](https://dl.acm.org/doi/pdf/10.1145/2810103.2813677)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd80cf2b",
   "metadata": {},
   "source": [
    "Today, we will explore three different techniques to preserve the privacy of the training data using the Adult dataset as an example."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82081359",
   "metadata": {},
   "source": [
    "# A. Load Data\n",
    "In will use the Adult data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20ee6802",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-29T06:24:24.877177Z",
     "start_time": "2024-11-29T06:24:24.835790Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f158101e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict\n",
    "\n",
    "data_types = OrderedDict([\n",
    "    (\"age\", \"int\"),\n",
    "    (\"workclass\", \"category\"),\n",
    "    (\"final_weight\", \"int\"),  # originally it was called fnlwgt\n",
    "    (\"education\", \"category\"),\n",
    "    (\"education_num\", \"int\"),\n",
    "    (\"marital_status\", \"category\"),\n",
    "    (\"occupation\", \"category\"),\n",
    "    (\"relationship\", \"category\"),\n",
    "    (\"race\", \"category\"),\n",
    "    (\"sex\", \"category\"),\n",
    "    (\"capital_gain\", \"float\"),  # required because of NaN values\n",
    "    (\"capital_loss\", \"int\"),\n",
    "    (\"hours_per_week\", \"int\"),\n",
    "    (\"native_country\", \"category\"),\n",
    "    (\"income_class\", \"category\"),\n",
    "])\n",
    "target_column = \"income_class\"\n",
    "\n",
    "def read_dataset(path):\n",
    "    return pd.read_csv(\n",
    "        path,\n",
    "        names=data_types,\n",
    "        index_col=None,\n",
    "\n",
    "        comment='|',  # test dataset has comment in it\n",
    "        skipinitialspace=True,  # Skip spaces after delimiter\n",
    "        na_values={\n",
    "            'capital_gain': 99999,\n",
    "            'workclass': '?',\n",
    "            'native_country': '?',\n",
    "            'occupation': '?',\n",
    "        },\n",
    "        dtype=data_types,\n",
    "    )\n",
    "\n",
    "def clean_dataset(data):\n",
    "    # Test dataset has dot at the end, we remove it in order\n",
    "    # to unify names between training and test datasets.\n",
    "    data['income_class'] = data.income_class.str.rstrip('.').astype('category')\n",
    "    \n",
    "    # Remove final weight column since there is no use\n",
    "    # for it during the classification.\n",
    "    data = data.drop('final_weight', axis=1)\n",
    "    \n",
    "    # Duplicates might create biases during the analysis and\n",
    "    # during prediction stage they might give over-optimistic\n",
    "    # (or pessimistic) results.\n",
    "    data = data.drop_duplicates()\n",
    "    \n",
    "    # Binary target variable (>50K == 1 and <=50K == 0)\n",
    "    data[target_column] = (data[target_column] == '>50K').astype(int)\n",
    "    \n",
    "    # Categorical dataset\n",
    "    categorical_features = data.select_dtypes('category').columns\n",
    "    data[categorical_features] = data.select_dtypes('category').apply(lambda x: x.cat.codes)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfbf8578",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get and clean train dataset\n",
    "TRAIN_DATA_FILE = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data'\n",
    "train_data = clean_dataset(read_dataset(TRAIN_DATA_FILE))\n",
    "train_data = train_data.dropna()\n",
    "print(\"Train dataset shape:\", train_data.shape)\n",
    "\n",
    "# get and clean test dataset\n",
    "TEST_DATA_FILE = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test'\n",
    "test_data = clean_dataset(read_dataset(TEST_DATA_FILE))\n",
    "test_data = test_data.dropna()\n",
    "print(\"Test dataset shape:\", test_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0117fab",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_column = \"income_class\"\n",
    "features = train_data.columns.difference([target_column]).tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53eeff7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=len(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336cf517",
   "metadata": {},
   "source": [
    "# A. Train a simple model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "780a74b5",
   "metadata": {},
   "source": [
    "scale features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1878324",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(train_data[features]),index=train_data.index,columns = features)\n",
    "y_train = train_data[[target_column]]\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(test_data[features]),index=test_data.index ,columns = features) # note that here we just use the transform method!\n",
    "y_test = test_data[[target_column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b968aeb7",
   "metadata": {},
   "source": [
    "train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70386bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train[target_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac191ed9",
   "metadata": {},
   "source": [
    "evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36ef4ac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = model.predict(X_test_scaled[features])\n",
    "accuracy = accuracy_score(y_true=test_data[target_column], y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d906084",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5b8042",
   "metadata": {},
   "source": [
    "# B. **Output Perturbation** - Randomized Response\n",
    "\n",
    "A simple method is to apply randomized response to the output of the model. \n",
    "Note that in this method, we assume that the adversary does not have access to the parameters of the model, but can only query the model ones. An example is when we deploy a machine learning model through an API, and the adversary can request predictions on this data ones.\n",
    "\n",
    "Randomized response flips the output of the model with some probability $ p $ for a binary response. \n",
    "If we want to ensure privacy with $ \\epsilon $-differential privacy guarantees, we need to set the probability of flipping as:\n",
    "\n",
    "$$\n",
    "p = \\frac{1}{e^\\epsilon + 1}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b62361d",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db120944",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(train_data[features]),index=train_data.index,columns = features)\n",
    "y_train = train_data[[target_column]]\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(test_data[features]),index=test_data.index ,columns = features) # note that here we just use the transform method!\n",
    "y_test = test_data[[target_column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5075bc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train[target_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df259bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = model.predict(X_test_scaled[features])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1969e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def randomised_response(prediction, epsilon):\n",
    "    # step 1. define the flip propability\n",
    "    p = \n",
    "    \n",
    "    # step 2. flip predictions\n",
    "    # hint: in order to flip the prediction we can generate a random number [0,1] and if is less than p we can flip\n",
    "    # otherwise we keep the true prediction\n",
    "    flip_mask = \n",
    "    noisy_predictions =   \n",
    "    \n",
    "    return noisy_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf0ad399",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_predictions = randomised_response(predictions, epsilon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd036076",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracyRR = accuracy_score(y_true=test_data[target_column], y_pred=noisy_predictions)\n",
    "accuracyRR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9745d31f",
   "metadata": {},
   "source": [
    "### Note on SGD with Output Perturbation\n",
    "\n",
    "Output perturbation preserves privacy only in scenarios where the adversary can query the model.  \n",
    "However, the concept of output perturbation can also be applied during model training.\n",
    "\n",
    "For instance, during training, we can generate predictions, add noise to them, \n",
    "and then compute the loss of the model based on these noisy predictions. \n",
    "The model is then optimized using SGD.\n",
    "\n",
    "###### This procedure ensures privacy even when the adversary has access to the parameters of the model so they can query the model more than ones."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6419fd17",
   "metadata": {},
   "source": [
    "# C. Data Perturbation\n",
    "\n",
    "On other simple technique to preserve privacy is to add noise to the dataset before training. In this approach, privacy is preserved thanks to the post-processing theorem, which ensures that after applying any differential privacy noise to the results, privacy is maintained for each subsequent maniplulation of the data.\n",
    "\n",
    "#### Theorem 2.6.2 [Post-processing].\n",
    "Let mechanism $ \\pi(a \\mid x) $ be $ \\epsilon $-DP. Applying any transformation $ f : A \\to Y $ to the output of the mechanism to obtain $ y = f(a) $, results in another $ \\epsilon $-DP mechanism.\n",
    "\n",
    "\n",
    "We will implement Laplacian noise, which adds Laplacian noise to the dataset.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3583fde",
   "metadata": {},
   "source": [
    "## Laplacian Mechanism\n",
    "\n",
    "To achieve differential privacy, we add noise to the dataset $D$, where the noise is drawn from a **Laplace distribution**.\n",
    "\n",
    "$$\n",
    "\\hat{D} = D + \\text{Lap}(0, b)\n",
    "$$\n",
    "\n",
    "where $ \\hat{D} $ is the noisy dataset, and $ \\text{Lap}(0, b) $ is Laplacian noise with mean 0 and scale $ b $.\n",
    "\n",
    "#### Noise Scale $ b $:\n",
    "\n",
    "The scale $ b $ of the Laplace distribution is related to the **sensitivity** $ \\Delta $ of the function and the privacy budget $ \\epsilon $:\n",
    "\n",
    "$$\n",
    "b = \\frac{\\Delta }{\\epsilon}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3606b36",
   "metadata": {},
   "source": [
    "We will implement the Laplacian mechanism on the dataset.\n",
    "\n",
    "###### Step 1:  Calculate $\\epsilon$ for each individual mechanism/feature.\n",
    "[Theorem 2.6.1 book]\n",
    "For any $ \\epsilon > 0 $,  if each mechanism is $ \\epsilon_i $-DP, the composed mechanism is $ \\sum_{i=1}^T \\epsilon_i $-DP.\n",
    "\n",
    "So for each feature we want to use $\\epsilon_i =  \\epsilon / N$\n",
    "\n",
    "\n",
    "###### Step 2:  Calculate the sensitivity of each feature.\n",
    "When we add noise in the dataset the sensitivty is the difference between the maximum and minimum value.\n",
    "######  Step 3:  Add Laplacian noise to each feature based on its sensitivity and privacy budget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ef0a391",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_laplacian_noise(epsilon, N, data):\n",
    "    # step 1. define epsilon for each feature\n",
    "    feature_epsilon = \n",
    "    \n",
    "    # step 2. caluclate sensitivity\n",
    "    sensitivity = \n",
    "    \n",
    "    # step 3. add noise for each feature\n",
    "    noisy_data = data.copy()\n",
    "    for feature in data[features].columns:\n",
    "        sensitivity_feature =\n",
    "        scale =\n",
    "        noise = \n",
    "        noisy_data[feature] = \n",
    "    return noisy_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37e83db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_data = add_laplacian_noise(epsilon,N, train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f39a53dc",
   "metadata": {},
   "source": [
    "preprossesing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da69ed0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(noisy_data[features]),index=noisy_data.index,columns = features)\n",
    "y_train = train_data[[target_column]]\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(test_data[features]),index=test_data.index ,columns = features) # note that here we just use the transform method!\n",
    "y_test = test_data[[target_column]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0bd87aa",
   "metadata": {},
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f3f5e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train_scaled, y_train[target_column])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc4d5b9f",
   "metadata": {},
   "source": [
    "evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2bba30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = model.predict(X_test_scaled[features])\n",
    "accuracy_data_noise = accuracy_score(y_true=test_data[target_column], y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf187193",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_data_noise"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf8db833",
   "metadata": {},
   "source": [
    "# D. Differentially private empirical risk minimization\n",
    "\n",
    "Differentially Private Empirical Risk Minimization is a framework that allows you to learn models from data while ensuring the privacy of individuals in the dataset. By adding noise to the loss function or optimization process, it ensures that the learned model does not reveal too much information about any single data point, providing differential privacy guarantees. The challenge lies in balancing the trade-off between privacy and the accuracy of the learned model.\n",
    "\n",
    "$$ \\hat{L} = Loss + noise $$\n",
    "\n",
    "The paper of the work can be found [here](https://jmlr.org/papers/volume12/chaudhuri11a/chaudhuri11a.pdf) \n",
    "\n",
    "We will use model from the following library: [Diffprivlib](https://diffprivlib.readthedocs.io/en/latest/)  \n",
    "\n",
    "To train a neural network with DP and pytorch you can use [Opacus library](https://opacus.ai/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab2cd7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = pd.DataFrame(scaler.fit_transform(train_data[features]),index=train_data.index,columns = features)\n",
    "y_train = train_data[[target_column]]\n",
    "X_test_scaled = pd.DataFrame(scaler.transform(test_data[features]),index=test_data.index ,columns = features) # note that here we just use the transform method!\n",
    "y_test = test_data[[target_column]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d7a8c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffprivlib.models import LogisticRegression as LogisticRegressionDP\n",
    "dp_model = LogisticRegressionDP(epsilon=epsilon)\n",
    "dp_model.fit(X_train_scaled, y_train[target_column])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d14ccb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "predictions = dp_model.predict(X_test_scaled[features])\n",
    "accuracy_DP_ERM = accuracy_score(y_true=test_data[target_column], y_pred=predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "501f4f54",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_DP_ERM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d930a7c",
   "metadata": {},
   "source": [
    "# Compare models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f48504cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "results= {\n",
    "            \"Simple Model\": accuracy,\n",
    "            \"private ERM\":accuracy_DP_ERM,\n",
    "            \"data noise\": accuracy_data_noise,\n",
    "            \"RR\":accuracyRR\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "261c912e",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008761bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(results,index=[1]).plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c843ee0e",
   "metadata": {},
   "source": [
    "### Effect of Epsilon\n",
    "\n",
    "As with fairness, there is a trade-off between privacy and accuracy. \n",
    "\n",
    "In this section, we examine the effect of epsilon on the model's accuracy. Specifically, for each value of epsilon defined below, we will train 50 models to calculate the average accuracy and the standard deviation of the performance metric. The results will then be plotted to visualize the differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43978171",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilons = np.logspace(-2, 2, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a953e2cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffprivlib.models import GaussianNB as private_GaussianNB\n",
    "\n",
    "# for different epsilon\n",
    "for epsilon in epsilons:\n",
    "    \n",
    "    # train the model 50 times\n",
    "    for _ in range(50):\n",
    "        \n",
    "        \n",
    "    # save mean/std for the model\n",
    "    acc_mean\n",
    "    acc_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b7954ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.semilogx(epsilons, acc_mean, label=\"DP model\")\n",
    "plt.fill_between(epsilons, \n",
    "                 np.array(acc_mean) - np.array(acc_std),\n",
    "                 np.array(acc_mean) + np.array(acc_std),\n",
    "                 alpha=0.2)\n",
    "plt.hlines(accuracy, 0.01, 100, linestyles = \"--\",color=\"red\", label=\"no privacy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy for Different $\\epsilon$\")\n",
    "plt.xlabel(\"$\\epsilon$\")\n",
    "plt.ylabel(\"accuracy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b05d004",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml-society",
   "language": "python",
   "name": "ml-society"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
