#+TITLE: Machine Learning and Data Mining, Master course
#+AUTHOR: Christos Dimitrakakis
#+EMAIL:christos.dimitrakakis@unine.ch
#+LaTeX_HEADER: \usepackage{tikz}
#+LaTeX_HEADER: \usepackage{amsmath}
#+LaTeX_HEADER: \usepackage{amssymb}
#+LaTeX_HEADER: \usepackage{isomath}
#+LaTeX_HEADER: \newcommand \E {\mathop{\mbox{\ensuremath{\mathbb{E}}}}\nolimits}
#+LaTeX_HEADER: \newcommand \Var {\mathop{\mbox{\ensuremath{\mathbb{V}}}}\nolimits}
#+LaTeX_HEADER: \newcommand \Bias {\mathop{\mbox{\ensuremath{\mathbb{B}}}}\nolimits}
#+LaTeX_HEADER: \newcommand\ind[1]{\mathop{\mbox{\ensuremath{\mathbb{I}}}}\left\{#1\right\}}
#+LaTeX_HEADER: \renewcommand \Pr {\mathop{\mbox{\ensuremath{\mathbb{P}}}}\nolimits}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmax}{arg\,max}
#+LaTeX_HEADER: \DeclareMathOperator*{\argmin}{arg\,min}
#+LaTeX_HEADER: \DeclareMathOperator*{\sgn}{sgn}
#+LaTeX_HEADER: \newcommand \defn {\mathrel{\triangleq}}
#+LaTeX_HEADER: \newcommand \Reals {\mathbb{R}}
#+LaTeX_HEADER: \newcommand \Param {\Theta}
#+LaTeX_HEADER: \newcommand \param {\theta}
#+LaTeX_HEADER: \newcommand \vparam {\vectorsym{\theta}}
#+LaTeX_HEADER: \newcommand \mparam {\matrixsym{\Theta}}
#+LaTeX_HEADER: \newcommand \bW {\matrixsym{W}}
#+LaTeX_HEADER: \newcommand \bw {\vectorsym{w}}
#+LaTeX_HEADER: \newcommand \wi {\vectorsym{w}_i}
#+LaTeX_HEADER: \newcommand \wij {w_{i,j}}
#+LaTeX_HEADER: \newcommand \bA {\matrixsym{A}}
#+LaTeX_HEADER: \newcommand \ai {\vectorsym{a}_i}
#+LaTeX_HEADER: \newcommand \aij {a_{i,j}}
#+LaTeX_HEADER: \newcommand \bx {\vectorsym{x}}
#+LaTeX_HEADER: \newcommand \bel {\beta}
#+LaTeX_HEADER: \newcommand \Ber {\textrm{Bernoulli}}
#+LaTeX_HEADER: \newcommand \Beta {\textrm{Beta}}
#+LaTeX_HEADER: \newcommand \Normal {\textrm{Normal}}
#+LaTeX_CLASS_OPTIONS: [smaller]
#+COLUMNS: %40ITEM %10BEAMER_env(Env) %9BEAMER_envargs(Env Args) %4BEAMER_col(Col) %10BEAMER_extra(Extra)
#+TAGS: activity advanced definition exercise homework project example theory code
#+OPTIONS:   H:3
* General
** Introduction
*** Summary
This course gives an introduction to the algorithms and theory of
machine learning. Application is in the form of a course project.
During the course, you will be able to:

- Formulate machine learning problems in terms of opimisation or probabilistic inference.
- Understand the fundamental machine learning algorithms.
- Be able to implement some of the simplest algorithms.
- Apply off-the-shelf algorithms from scikit-learn to problems.
- Develop custom models using the pyTorch library.

The course focuses on algorithms and models, firstly on
optimisation-based learning, and the secondly on probabilistic
learning.


*** Schedule


|--------+-------+-----------------------------------+--------------------------------------------------+---------------------+---------|
| Module |  Date | Topic                             | Details                                          | Python              | Type    |
|--------+-------+-----------------------------------+--------------------------------------------------+---------------------+---------|
|      1 | 09.20 | Introduction                      | Mean estimation, kNN, Train/Test                 | nympy, pandas       | Mixed   |
|      2 | 09.27 | The Perceptron and Generalisation | The Perceptron, Generalisation, Simulation       | pandas, scikitlearn | Lecture |
|      3 | 10.04 | Model Comparison                  | Cross-Validation, Bootstrapping, Model Selection | scikit learn        | Lab (1) |
|      4 | 10.11 | Regression, Neural Networks       | Linear regression, SGD                           |                     | Mix     |
|      5 | 10.18 | Multi-Layer Perceptrons           | Backpropagation, Softmax, RELU                   |                     | Mix     |
|      6 | 10.25 | Generative Models                 | Beta-Bernoulli, Naive Bayes and Beyond           |                     | Lecture |
|      7 | 11.01 | Bayes Nets                        | Markov Models, Tree Models, CRFs,                | Text prediction     | Mix     |
|--------+-------+-----------------------------------+--------------------------------------------------+---------------------+---------|
|      8 | 11.08 | Fairness 1                        |                                                  |                     |         |
|      9 | 11.15 | Fairness 2                        |                                                  |                     |         |
|--------+-------+-----------------------------------+--------------------------------------------------+---------------------+---------|
|     10 | 11.22 | Privacy 1                         |                                                  |                     |         |
|     11 | 11.29 | Privacy 2                         |                                                  |                     |         |
|--------+-------+-----------------------------------+--------------------------------------------------+---------------------+---------|
|     12 | 11.06 | Project Work                      |                                                  |                     |         |
|--------+-------+-----------------------------------+--------------------------------------------------+---------------------+---------|
|     13 | 12.13 | Project Presentations             |                                                  |                     | Lab     |
|--------+-------+-----------------------------------+--------------------------------------------------+---------------------+---------|
|     14 | 12.20 | NA                                |                                                  |                     |         |
|--------+-------+-----------------------------------+--------------------------------------------------+---------------------+---------|


1. kNN, learning and generalisation.
2. The Perceptron algorithm. Gradient Descent Convergence. Pandas/scikit.
3. MLP
4. Bayesian learning.
5. Bayesian networks.
6. Online learning: Prediction with expert advice.
7. Concentration inequalities and learning theory.
8. Fairness and discrimination: conditional independence.
9. Fairness and meritocracy: smoothness.
10. Differential privacy and randomised response.
11. Laplace and Exponential mechanisms.
12. Experiment design lab
13. Project presentations.

** Material
*** Textbooks
**** Primary
- Introduction to Statistical Learning with Python
https://hastie.su.domains/ISLP/ISLP_website.pdf
- Elements of Statistical Learning
https://hastie.su.domains/Papers/ESLII.pdf
**** Secondary
- Probabilistic Machine Learning: An Introduction
https://probml.github.io/pml-book/book1.html
https://github.com/probml/pml-book/releases/latest/download/book1.pdf
- Probabilistic Machine Learning: Advanced Topics
https://probml.github.io/pml-book/book2.html
https://github.com/probml/pml2-book/releases/latest/download/book2.pdf



**** Links to reference material

ISLP: Introduction to Statistical Learning with Python
ESL2: Elements of Statistical Learning (2nd Ed)
PML1: Probabilistic Machine Learning: An Introduction
PML2: Probabilistic Machine Learning: Advanced Topics

|-----------------------------+------+------+------+------|
| Topic                       | ISLP | ESL2 | PML1 | PML2 |
|-----------------------------+------+------+------+------|
| Linear Regression           |    3 |    3 |      |      |
| Nearest Neighbours          |  3,4 |   13 |      |      |
| Linear Classification       |    4 |    4 |      |      |
| Model Selection             |    5 |    7 |      |      |
| Linear Model Regularization |    6 |    3 |      |      |
| Basis Expansions            |    7 |    5 |      |      |
| Kernel Smoothing            |    7 |    6 |      |      |
| Additive Models             |    7 |    9 |      |      |
| Model Inference/Averaging   |    8 |    8 |      |      |
| Random Forests              |    8 |   15 |      |      |
| Ensemble Learning           |    8 |   16 |      |      |
| Trees                       |    8 |    9 |      |      |
| Boosting                    |    8 |   10 |      |      |
| Expectation Maximisation    |    * |    8 |      |  6.5 |
| SVMs                        |    9 |   12 |      |      |
| Neural Netowrks             |   10 |   11 |      |      |
| Censored Data               |   11 |   18 |      |      |
| Unsupervised Learning       |   12 |   14 |      |      |
| Undirected Graphical Models |    * |   17 |      |      |
| Hypothesis tesing           |   13 |   18 |      |      |
| High-Dimensional Statisitcs |    6 |   18 |      |      |
|-----------------------------+------+------+------+------|

* Project grading
Criteria for full marks in each part of the project are the following. 

1. Documenting of the work in a way that enables reproduction.
2. Technical correctness of their analysis.
3. Demonstrating that they have understood the assumptions underlying their analysis.
4. Addressing issues of reproducibility in research.
5. Addressing scientific and ethical questions where applicable, and if not, clearly explain why they are not.
6. Consulting additional resources beyond the source material with proper citations.

The follow marking guidelines are what one would expect from students attaining each grade. 


*** A (6)


1. Submission of a detailed report from which one can definitely reconstruct their work without referring to their code. There should be no ambiguities in the described methodology. Well-documented code where design decisions are explained. 
2. Extensive analysis and discussion. Technical correctness of their analysis. Nearly error-free implementation.
3. The report should detail what models are used and what the assumptions are behind them. The conclusions of the should include appropriate caveats.  When the problem includes simple decision making, the optimality metric should be well-defined and justified. Simiarly, when well-defined optimality criteria should given for the experiment design, when necessary. The design should be (to some degree of approximation, depending on problem complexity) optimal according to this criteria.
4. Appropriate methods to measure reproducibility. Use of cross-validation or hold-out sets to measure performance. Use of an unbiased methodology for algorithm, model or parameter selection. Appropriate reporting of a confidence level (e.g. using bootstrapping) in their analytical results. Relevant assumptions are mentioned when required.
5. A clear definition of a scientific question. When dealing with data relating to humans, ethical concerns, such as privacy and/or fairness should be addressed.
6. The report contains some independent thinking, or includes additional resources beyond the source material with proper citations. The students go beyond their way to research material and implement methods not discussed in the course.

*** B (5.5)

1. Submission of a report from which one can plausibly reconstruct their work without referring to their code. There should be no major ambiguities in the described methodology. 
2. Technical correctness of their analysis, with a good discussion. Possibly minor errors in the implementation.
3. The report should detail what models are used, as well as the optimality criteria, including for the experiment design. The conclusions of the report must contain appropriate caveats. 
4. Use of cross-validation or hold-out sets to measure performance. Use of an unbiased methodology for algorithm, model or parameter selection. 
5. When dealing with data relating to humans, ethical concerns such as privacy and/or fairness should be addressed. While an analysis of this issue may not be performed, there is a substantial discussion of the issue that clearly shows understanding by the student.
6. The report contains some independent thinking, or the students mention other methods beyond the source material, with proper citations, but do not further investigate them.
   
*** C (5)

1. Submission of a report from which one can partially reconstruct most of their work without referring to their code. There might be some ambiguities in parts of the described methodology. 
2. Technical correctness of their analysis, with an adequate discussion. Some errors in a part of the implementation.
3. The report should detail what models are used, as well as the optimality criteria and the choice of experiment design. Analysis caveats are not included.
4. Either use of cross-validation or hold-out sets to measure performance, or use of an unbiased methodology for algorithm, model or parameter selection - but in a possibly inconsistent manner.
5. When dealing with data relating to humans, ethical issues are addressed superficially.
6. There is little mention of methods beyond the source material or independent thinking.

*** D (4.5)

1. Submission of a report from which one can partially reconstruct most of their work without referring to their code. There might be serious ambiguities in parts of the described methodology. 
2. Technical correctness of their analysis with limited discussion. Possibly major errors in a part of the implementation.
3. The report should detail what models are used, as well as the optimality criteria. Analysis caveats are not included.
4. Either use of cross-validation or hold-out sets to measure performance, or use of an unbiased methodology for algorithm, model or parameter selection - but in a possibly inconsistent manner.
5. When dealing with data relating to humans, ethical issues are addressed superficially or not at all.
6. There is little mention of methods beyond the source material or independent thinking.

*** E (4)
1. Submission of a report from which one can obtain a high-level idea of their work without referring to their code. There might be serious ambiguities in all of the described methodology. 
2. Technical correctness of their analysis with very little discussion. Possibly major errors in only a part of the implementation.
3. The report might mention what models are used or the optimality criteria, but not in sufficient detail and caveats are not mentioned.
4. Use of cross-validation or hold-out sets to simultaneously measure performance and optimise hyperparameters, but possibly in a way that introduces some bias.
5. When dealing with data relating to humans, ethical issues are not discussed.
6. There is no mention of methods beyond the source material or independent thinking.

*** F (<3)

1. The report does not adequately explain their work.
2. There is very little discussion and major parts of the analysis are technically incorrect, or there are errors in the implementation.
3. The models used might be mentioned, but not any other details.
4. There is no effort to ensure reproducibility or robustness.
5. When applicable: Ethical issues are not mentioned.
6. There is no mention of methods beyond the source material or independent thinking.
